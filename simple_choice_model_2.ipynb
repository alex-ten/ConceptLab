{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T11:28:49.241832Z",
     "start_time": "2019-08-16T11:28:49.147885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The snakeviz extension is already loaded. To reload it, use:\n",
      "  %reload_ext snakeviz\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext snakeviz\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from supplementary.simple_choice_model import hits_gen as hits\n",
    "from supplementary.simple_choice_model import sim_tools\n",
    "import ipywidgets as wid\n",
    "import loc_utils as lut\n",
    "\n",
    "import vis_utils as vut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from IPython.display import display\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "colors = ['#43799d', '#cc5b46', '#ffbb00', '#71bc78', '#43799d', '#cc5b46', '#ffbb00', '#71bc78']\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def temp_seed(seed):\n",
    "    state = np.random.get_state()\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        np.random.set_state(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating population parameters from individual-level data (via negative log of trial-wise composite likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T13:56:39.871015Z",
     "start_time": "2019-08-16T13:56:35.217913Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>theta</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grp</th>\n",
       "      <th>ntm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>26.95532</td>\n",
       "      <td>0.15880</td>\n",
       "      <td>0.29659</td>\n",
       "      <td>0.69673</td>\n",
       "      <td>-0.41150</td>\n",
       "      <td>7.94423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.33708</td>\n",
       "      <td>-0.02072</td>\n",
       "      <td>0.09978</td>\n",
       "      <td>0.72372</td>\n",
       "      <td>-0.58023</td>\n",
       "      <td>7.94853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.11903</td>\n",
       "      <td>0.13616</td>\n",
       "      <td>-0.18940</td>\n",
       "      <td>0.74029</td>\n",
       "      <td>-0.54902</td>\n",
       "      <td>7.44947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>24.75883</td>\n",
       "      <td>0.11222</td>\n",
       "      <td>-0.24730</td>\n",
       "      <td>0.78917</td>\n",
       "      <td>-0.29117</td>\n",
       "      <td>7.49193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.51072</td>\n",
       "      <td>0.06113</td>\n",
       "      <td>-0.30924</td>\n",
       "      <td>0.74885</td>\n",
       "      <td>-0.51468</td>\n",
       "      <td>7.24357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.67370</td>\n",
       "      <td>0.12082</td>\n",
       "      <td>-0.41099</td>\n",
       "      <td>0.77443</td>\n",
       "      <td>-0.57813</td>\n",
       "      <td>6.99315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss    alpha     beta   gamma    theta     tau\n",
       "grp ntm                                                    \n",
       "0   1   26.95532  0.15880  0.29659 0.69673 -0.41150 7.94423\n",
       "    2   30.33708 -0.02072  0.09978 0.72372 -0.58023 7.94853\n",
       "    3   35.11903  0.13616 -0.18940 0.74029 -0.54902 7.44947\n",
       "1   1   24.75883  0.11222 -0.24730 0.78917 -0.29117 7.49193\n",
       "    2   35.51072  0.06113 -0.30924 0.74885 -0.51468 7.24357\n",
       "    3   33.67370  0.12082 -0.41099 0.77443 -0.57813 6.99315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "def neg_log_likelihood(params, *args):\n",
    "    coeffs = np.array(params[:-1])\n",
    "    inps = np.stack(args[:-1], axis=0)\n",
    "    U = (coeffs[:, None, None] * inps).sum(axis=0)\n",
    "    exponent = np.exp(U * params[-1])\n",
    "    P = (exponent.T / np.sum(exponent, axis=1)).T\n",
    "    logP = np.log(P[args[-1].astype(bool)])\n",
    "    logL = np.sum(logP, axis=0)\n",
    "    return -logL\n",
    "\n",
    "# Estimate the params\n",
    "df = lut.unpickle('supplementary/simple_choice_model/data/fit_data.pkl')\n",
    "df = df.loc[df.ntm != 0, :]\n",
    "data_dict = {'sid': [], 'grp': [], 'ntm': [], 'loss': [], \n",
    "             'alpha': [], 'beta': [], 'gamma': [], 'theta': [], 'tau': []}\n",
    "alpha_bounds = [-1, 1]\n",
    "beta_bounds = [-1, 1]\n",
    "gamma_bounds = [0, 1]\n",
    "theta_bounds = [-1, 0]\n",
    "tau_bounds = [1, 10]\n",
    "\n",
    "bounds = (alpha_bounds, beta_bounds, gamma_bounds, theta_bounds, tau_bounds)\n",
    "init_guess = sim_tools.rand_params(bounds)\n",
    "\n",
    "for i, sdf in df.groupby('sid'):\n",
    "    sid, grp, ntm = sdf.sid.values[0], sdf.grp.values[0], sdf.ntm.values[0]\n",
    "    lps = sdf.loc[:, 'lp1':'lp4'].values[1:, :]\n",
    "    pcs = sdf.loc[:, 'pc1':'pc4'].values[1:, :]\n",
    "    ins = sdf.loc[:, 'in1':'in4'].values[1:, :]\n",
    "    chs = sdf.loc[:, 'ch1':'ch4'].values[1:, :]\n",
    "    time_alloc = (sdf.loc[:, 'ch1':'ch4'].values[1:, :].cumsum(axis=0) + 15)\n",
    "    trs = (time_alloc.T / time_alloc.sum(axis=1)).T\n",
    "\n",
    "    data = (lps, pcs, ins, trs, chs)\n",
    "    x, f, d = sp.optimize.fmin_l_bfgs_b(func=neg_log_likelihood, x0=init_guess, args=data,\n",
    "                                    approx_grad=True, disp=False, bounds=bounds)\n",
    "\n",
    "    # Store params   \n",
    "    data_dict['sid'].append(sid)\n",
    "    data_dict['grp'].append(grp)\n",
    "    data_dict['ntm'].append(ntm)\n",
    "    data_dict['loss'].append(f)\n",
    "    data_dict['alpha'].append(x[0])\n",
    "    data_dict['beta'].append(x[1])\n",
    "    data_dict['gamma'].append(x[2])\n",
    "    data_dict['theta'].append(x[3])\n",
    "    data_dict['tau'].append(x[4])\n",
    "\n",
    "# Calculate parameter stats\n",
    "fdf = pd.DataFrame(data_dict)\n",
    "gfdf = fdf.groupby(['grp','ntm']).mean().drop(columns=['sid'])\n",
    "display(gfdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T13:04:23.411585Z",
     "start_time": "2019-08-16T13:03:53.880177Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5deb6c742464d38a630a66999a2fe0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aic</th>\n",
       "      <th>bic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>form</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LP + PC + I + TR</th>\n",
       "      <td>93.87194</td>\n",
       "      <td>146.57337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC + I + TR</th>\n",
       "      <td>95.75397</td>\n",
       "      <td>148.45540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP + PC + I</th>\n",
       "      <td>96.69262</td>\n",
       "      <td>149.39405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP + I + TR</th>\n",
       "      <td>97.78605</td>\n",
       "      <td>150.48748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC + I</th>\n",
       "      <td>98.62696</td>\n",
       "      <td>151.32839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP + I</th>\n",
       "      <td>99.75707</td>\n",
       "      <td>152.45850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I + TR</th>\n",
       "      <td>100.39001</td>\n",
       "      <td>153.09144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>101.76421</td>\n",
       "      <td>154.46565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP + PC + TR</th>\n",
       "      <td>576.22747</td>\n",
       "      <td>628.92890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP + PC</th>\n",
       "      <td>576.87434</td>\n",
       "      <td>629.57578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC + TR</th>\n",
       "      <td>608.89213</td>\n",
       "      <td>661.59356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC</th>\n",
       "      <td>609.50776</td>\n",
       "      <td>662.20919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP + TR</th>\n",
       "      <td>674.25441</td>\n",
       "      <td>726.95584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP</th>\n",
       "      <td>674.45814</td>\n",
       "      <td>727.15957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TR</th>\n",
       "      <td>717.60200</td>\n",
       "      <td>770.30343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       aic       bic\n",
       "form                                \n",
       "LP + PC + I + TR  93.87194 146.57337\n",
       "PC + I + TR       95.75397 148.45540\n",
       "LP + PC + I       96.69262 149.39405\n",
       "LP + I + TR       97.78605 150.48748\n",
       "PC + I            98.62696 151.32839\n",
       "LP + I            99.75707 152.45850\n",
       "I + TR           100.39001 153.09144\n",
       "I                101.76421 154.46565\n",
       "LP + PC + TR     576.22747 628.92890\n",
       "LP + PC          576.87434 629.57578\n",
       "PC + TR          608.89213 661.59356\n",
       "PC               609.50776 662.20919\n",
       "LP + TR          674.25441 726.95584\n",
       "LP               674.45814 727.15957\n",
       "TR               717.60200 770.30343"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def neg_log_likelihood(params, *args):\n",
    "    coeffs = np.array(params[:-1])\n",
    "    inps = np.stack(args[:-1], axis=0)\n",
    "    U = (coeffs[:, None, None] * inps).sum(axis=0)\n",
    "    exponent = np.exp(U * params[-1])\n",
    "    P = (exponent.T / np.sum(exponent, axis=1)).T\n",
    "    logP = np.log(P[args[-1].astype(bool)])\n",
    "    logL = np.sum(logP, axis=0)\n",
    "    return -logL\n",
    "\n",
    "# Estimate the params\n",
    "df = lut.unpickle('supplementary/simple_choice_model/data/fit_data.pkl')\n",
    "df = df.loc[df.ntm != 0, :]\n",
    "data_dict = {'form': [], 'sid': [], 'grp': [], 'ntm': [], 'loss': [], 'aic': [], 'bic': [],\n",
    "             'alpha': [], 'beta': [], 'gamma': [], 'theta': [], 'tau': []}\n",
    "varnames = np.array(('LP', 'PC', 'I', 'TR'))\n",
    "alpha_bounds = [-1, 1]\n",
    "beta_bounds = [-1, 1]\n",
    "gamma_bounds = [0, 1]\n",
    "theta_bounds = [-1, 0]\n",
    "tau_bounds = [1, 50]\n",
    "\n",
    "bounds = (alpha_bounds, beta_bounds, gamma_bounds, theta_bounds, tau_bounds)\n",
    "models, inds = [], [0,1,2,3]\n",
    "for s in range(1,len(inds)+1):\n",
    "    models += combinations(inds, s)\n",
    "\n",
    "grouped = df.groupby('sid')\n",
    "with tqdm_notebook(total=len(grouped)) as progbar:\n",
    "    for i, sdf in grouped:\n",
    "        sid, grp, ntm = sdf.sid.values[0], sdf.grp.values[0], sdf.ntm.values[0]\n",
    "        lps = sdf.loc[:, 'lp1':'lp4'].values[1:, :]\n",
    "        pcs = sdf.loc[:, 'pc1':'pc4'].values[1:, :]\n",
    "        ins = sdf.loc[:, 'in1':'in4'].values[1:, :]\n",
    "        chs = sdf.loc[:, 'ch1':'ch4'].values[1:, :]\n",
    "        time_alloc = (sdf.loc[:, 'ch1':'ch4'].values[1:, :].cumsum(axis=0) + 15)\n",
    "        trs = (time_alloc.T / time_alloc.sum(axis=1)).T\n",
    "\n",
    "        data = (lps, pcs, ins, trs, chs)\n",
    "        init_guess = sim_tools.rand_params(bounds).tolist()\n",
    "\n",
    "        for model in models:\n",
    "            subdata = [data[mi] for mi in model] + [data[-1]]\n",
    "            subguess = [init_guess[mi] for mi in model] + [init_guess[-1]]\n",
    "            subbounds = [bounds[mi] for mi in model] + [bounds[-1]]\n",
    "\n",
    "            x, f, d = sp.optimize.fmin_l_bfgs_b(func=neg_log_likelihood, x0=subguess, args=tuple(subdata),\n",
    "                                            approx_grad=True, disp=False, bounds=subbounds)\n",
    "\n",
    "            # Store params\n",
    "            vec = np.full(5, np.nan)\n",
    "            vec[tuple([model])] = x[:-1]\n",
    "            vec[-1] = x[-1]\n",
    "            data_dict['form'].append(' + '.join(varnames[tuple([model])]))\n",
    "            data_dict['sid'].append(sid)\n",
    "            data_dict['grp'].append(grp)\n",
    "            data_dict['ntm'].append(ntm)\n",
    "            data_dict['loss'].append(f)\n",
    "            data_dict['aic'].append(2*f + 2*len(models))\n",
    "            data_dict['bic'].append(2*f + np.log(chs.shape[0])*len(models))\n",
    "            data_dict['alpha'].append(vec[0])\n",
    "            data_dict['beta'].append(vec[1])\n",
    "            data_dict['gamma'].append(vec[2])\n",
    "            data_dict['theta'].append(vec[3])\n",
    "            data_dict['tau'].append(vec[4])\n",
    "        progbar.update()\n",
    "\n",
    "# Calculate parameter stats\n",
    "fdf = pd.DataFrame(data_dict)\n",
    "gfdf = fdf.groupby(['form']).mean()[['aic', 'bic']]\n",
    "display(gfdf.sort_values(by='bic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize empirical data\n",
    "plt.close()\n",
    "fig = plt.figure('Fitting individuals', figsize=[9,4])\n",
    "ax_ = vut.pretty(fig.add_subplot(2,3,3))\n",
    "group_choices = df.groupby(['grp', 'trial']).mean()\n",
    "for grp in [0, 1]:\n",
    "    ax = vut.pretty(fig.add_subplot(2,3,grp+1))\n",
    "    ax.set_title('% selection across time ({})'.format('FS'[grp]))\n",
    "    ax.set_ylim(0,.7)\n",
    "    if not grp: ax.set_ylabel('Empirical data')\n",
    "        \n",
    "    for tid in [1, 2, 3, 4]:   \n",
    "        ax.plot(group_choices.loc[(grp, slice(None)), 'ch{}'.format(tid)].values, color = colors[tid-1])\n",
    "    \n",
    "    ax_.set_title('Total time allocation')\n",
    "    ax_.plot(group_choices.loc[(grp, slice(None)), 'ch1':'ch4'].values.mean(axis=0), \n",
    "            color=['#008fd5', '#fc4f30'][grp], label='FS'[grp], lw=2)\n",
    "    ax_.set_xticks([0,1,2,3])\n",
    "    ax_.set_xticklabels(['1D', 'I1D', '2D', 'R'])\n",
    "    ax_.set_ylim(0,.7)\n",
    "ax_.legend()\n",
    "    \n",
    "# Visualize data generated by simulation with estimated parameters\n",
    "df = lut.unpickle('supplementary/simple_choice_model/data/fit_data.pkl')\n",
    "df = df.loc[df.ntm != 0, :]\n",
    "N_trials = 250\n",
    "group_sizes = (df.groupby(['grp','ntm','sid']).count()/249).reset_index().groupby(['grp','ntm']).count()\n",
    "N_runs = 5\n",
    "\n",
    "runs_data = {0: [], 1: []}\n",
    "for run in range(N_runs):\n",
    "    for grp in [0, 1]:\n",
    "        grp_simdata = []\n",
    "        for ntm in [1, 2, 3]:\n",
    "            sids = df.loc[(df.grp==grp) & (df.ntm==ntm), 'sid'].unique()\n",
    "            N_sim = group_sizes.loc[(grp, ntm), 'sid']\n",
    "            sids = np.random.choice(sids, size=N_sim)\n",
    "            hits_params = hits.get_parametric(grp=grp, ntm=ntm)\n",
    "            trials = np.arange(N_trials) + 1\n",
    "            probs = np.stack([1 / (1 + np.exp(-(hits_params[tid][0] + hits_params[tid][1]*trials))) for tid in [1,2,3,4]], axis=1)\n",
    "            simhits = (np.random.rand(N_sim, N_trials, 4) <= probs).astype(int)\n",
    "            init_data = sim_tools.get_multiple_sids(sids)\n",
    "\n",
    "            simdata = []\n",
    "            for i, sid in enumerate(sids):\n",
    "                alpha, beta, gamma, theta, tau = fdf.set_index('sid').loc[sid, 'alpha':'tau'].values\n",
    "                choices = sim_tools.simple_simulation(init_state=init_data[i, :, :], \n",
    "                                                      win1=10, win2=9, N=N_trials, \n",
    "                                                      hits = simhits[i, :, :], \n",
    "                                                      alpha=alpha, beta=beta, \n",
    "                                                      gamma=gamma, theta=theta, tau=tau,\n",
    "                                                      inverse_temp=True)\n",
    "                simdata.append(np.eye(4)[choices.astype(int)])\n",
    "            grp_simdata.append(np.stack(simdata, axis=0).mean(axis=0))\n",
    "        runs_data[grp].append(np.stack(grp_simdata, axis=0).mean(axis=0))\n",
    "\n",
    "ax_ = vut.pretty(fig.add_subplot(2,3,6))\n",
    "for grp in [0, 1]:\n",
    "    mean_runs_data = np.stack(runs_data[grp], axis=0).mean(axis=0)\n",
    "    se_runs_data = sp.stats.sem(np.stack(runs_data[grp], axis=0), axis=0)\n",
    "    \n",
    "    # Plot simulated percent selection across time\n",
    "    ax = vut.pretty(fig.add_subplot(2,3,grp+4))\n",
    "    ax.set_ylim(0,.7)\n",
    "    if not grp: ax.set_ylabel('Simulated data')\n",
    "    for tid in [1, 2, 3, 4]:   \n",
    "        ax.plot(mean_runs_data[:, tid-1], color = colors[tid-1])\n",
    "        ax.fill_between(np.arange(mean_runs_data.shape[0]), \n",
    "                        mean_runs_data[:, tid-1]+se_runs_data[:, tid-1], \n",
    "                        mean_runs_data[:, tid-1]-se_runs_data[:, tid-1], \n",
    "                        color = colors[tid-1], alpha=.3)\n",
    "        \n",
    "    # Plot simulated TIME ALLOCATION\n",
    "    ax_.plot(mean_runs_data.mean(axis=0), color=['#008fd5', '#fc4f30'][grp], lw=2)\n",
    "    ax_.fill_between([0,1,2,3], \n",
    "                        mean_runs_data.mean(axis=0)+se_runs_data.mean(axis=0), \n",
    "                        mean_runs_data.mean(axis=0)-se_runs_data.mean(axis=0), \n",
    "                        color = ['#008fd5', '#fc4f30'][grp], alpha=.3)\n",
    "    ax_.set_xticks([0,1,2,3])\n",
    "    ax_.set_xticklabels(['1D', 'I1D', '2D', 'R'])\n",
    "    ax_.set_ylim(0,.7)\n",
    "    \n",
    "# fig.savefig('fitted_runs_LP_PC_I_TR_temp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Qualitative evaluation of individual fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T09:03:27.211545Z",
     "start_time": "2019-08-08T08:56:21.214167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>theta</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grp</th>\n",
       "      <th>ntm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.00000</th>\n",
       "      <th>1.00000</th>\n",
       "      <td>26.41085</td>\n",
       "      <td>0.09644</td>\n",
       "      <td>0.14230</td>\n",
       "      <td>0.26314</td>\n",
       "      <td>-0.22289</td>\n",
       "      <td>47.64495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00000</th>\n",
       "      <td>29.97449</td>\n",
       "      <td>0.00084</td>\n",
       "      <td>0.05753</td>\n",
       "      <td>0.28611</td>\n",
       "      <td>-0.27455</td>\n",
       "      <td>46.03194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00000</th>\n",
       "      <td>35.03755</td>\n",
       "      <td>0.07498</td>\n",
       "      <td>-0.05362</td>\n",
       "      <td>0.26680</td>\n",
       "      <td>-0.22383</td>\n",
       "      <td>43.17138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1.00000</th>\n",
       "      <th>1.00000</th>\n",
       "      <td>24.69040</td>\n",
       "      <td>0.03072</td>\n",
       "      <td>-0.07529</td>\n",
       "      <td>0.29928</td>\n",
       "      <td>-0.15761</td>\n",
       "      <td>47.36352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00000</th>\n",
       "      <td>35.31411</td>\n",
       "      <td>0.05033</td>\n",
       "      <td>-0.10388</td>\n",
       "      <td>0.29073</td>\n",
       "      <td>-0.20764</td>\n",
       "      <td>43.97381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00000</th>\n",
       "      <td>33.67059</td>\n",
       "      <td>0.03429</td>\n",
       "      <td>-0.13606</td>\n",
       "      <td>0.26228</td>\n",
       "      <td>-0.22331</td>\n",
       "      <td>42.98296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    loss   alpha     beta   gamma    theta      tau\n",
       "grp     ntm                                                        \n",
       "0.00000 1.00000 26.41085 0.09644  0.14230 0.26314 -0.22289 47.64495\n",
       "        2.00000 29.97449 0.00084  0.05753 0.28611 -0.27455 46.03194\n",
       "        3.00000 35.03755 0.07498 -0.05362 0.26680 -0.22383 43.17138\n",
       "1.00000 1.00000 24.69040 0.03072 -0.07529 0.29928 -0.15761 47.36352\n",
       "        2.00000 35.31411 0.05033 -0.10388 0.29073 -0.20764 43.97381\n",
       "        3.00000 33.67059 0.03429 -0.13606 0.26228 -0.22331 42.98296"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def neg_log_likelihood(params, *args):\n",
    "    a, b, c, d, t = params\n",
    "    LP, PC, I, TR, choices = args\n",
    "    U = a*LP + b*PC + c*I + d*TR\n",
    "    P = (np.exp(U * t).T / np.sum(np.exp(U * t), axis=1)).T\n",
    "    logP = np.log(P[choices.astype(bool)])\n",
    "    logL = np.sum(logP, axis=0)\n",
    "    return -logL\n",
    "\n",
    "# Estimate the params\n",
    "df = lut.unpickle('supplementary/simple_choice_model/data/fit_data.pkl')\n",
    "df = df.loc[df.ntm != 0, :]\n",
    "data_dict = {'sid': [], 'grp': [], 'ntm': [], 'loss': [], \n",
    "             'alpha': [], 'beta': [], 'gamma': [], 'theta': [], 'tau': []}\n",
    "alpha_bounds = [-1, 1]\n",
    "beta_bounds = [-1, 1]\n",
    "gamma_bounds = [0, 1]\n",
    "theta_bounds = [-1, 0]\n",
    "tau_bounds = [1, 100]\n",
    "\n",
    "bounds = (alpha_bounds, beta_bounds, gamma_bounds, theta_bounds, tau_bounds)\n",
    "\n",
    "gfdfs = []\n",
    "for run in range(50):\n",
    "    for i, sdf in df.groupby('sid'):\n",
    "        loss_hist = []\n",
    "        sid, grp, ntm = sdf.sid.values[0], sdf.grp.values[0], sdf.ntm.values[0]\n",
    "        lps = sdf.loc[:, 'lp1':'lp4'].values[1:, :]\n",
    "        pcs = sdf.loc[:, 'pc1':'pc4'].values[1:, :]\n",
    "        ins = sdf.loc[:, 'in1':'in4'].values[1:, :]\n",
    "        chs = sdf.loc[:, 'ch1':'ch4'].values[1:, :]\n",
    "        time_alloc = (sdf.loc[:, 'ch1':'ch4'].values[1:, :].cumsum(axis=0) + 15)\n",
    "        trs = (time_alloc.T / time_alloc.sum(axis=1)).T\n",
    "\n",
    "        data = (lps, pcs, ins, trs, chs)\n",
    "        init_guess = sim_tools.rand_params(bounds)\n",
    "\n",
    "        x, f, d = sp.optimize.fmin_l_bfgs_b(func=neg_log_likelihood, x0=init_guess, args=data,\n",
    "                                        approx_grad=True, disp=False, bounds=bounds,\n",
    "                                        callback=lambda xk: loss_hist.append([xk, neg_log_likelihood(xk, *data)]))\n",
    "        # Store params   \n",
    "        data_dict['sid'].append(sid)\n",
    "        data_dict['grp'].append(grp)\n",
    "        data_dict['ntm'].append(ntm)\n",
    "        data_dict['loss'].append(f)\n",
    "        data_dict['alpha'].append(x[0])\n",
    "        data_dict['beta'].append(x[1])\n",
    "        data_dict['gamma'].append(x[2])\n",
    "        data_dict['theta'].append(x[3])\n",
    "        data_dict['tau'].append(x[4])\n",
    "\n",
    "    # Calculate parameter stats\n",
    "    fdf = pd.DataFrame(data_dict)\n",
    "    gfdf = fdf.groupby(['grp','ntm']).mean().drop(columns=['sid'])\n",
    "    gfdfs.append(gfdf.reset_index().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T09:08:29.796129Z",
     "start_time": "2019-08-08T09:08:29.710076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>theta</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grp</th>\n",
       "      <th>ntm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.00000</th>\n",
       "      <th>1.00000</th>\n",
       "      <td>26.41085</td>\n",
       "      <td>0.09644</td>\n",
       "      <td>0.14230</td>\n",
       "      <td>0.26314</td>\n",
       "      <td>-0.22289</td>\n",
       "      <td>47.64495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00000</th>\n",
       "      <td>29.97449</td>\n",
       "      <td>0.00084</td>\n",
       "      <td>0.05753</td>\n",
       "      <td>0.28611</td>\n",
       "      <td>-0.27455</td>\n",
       "      <td>46.03194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00000</th>\n",
       "      <td>35.03755</td>\n",
       "      <td>0.07498</td>\n",
       "      <td>-0.05362</td>\n",
       "      <td>0.26680</td>\n",
       "      <td>-0.22383</td>\n",
       "      <td>43.17138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1.00000</th>\n",
       "      <th>1.00000</th>\n",
       "      <td>24.69040</td>\n",
       "      <td>0.03072</td>\n",
       "      <td>-0.07529</td>\n",
       "      <td>0.29928</td>\n",
       "      <td>-0.15761</td>\n",
       "      <td>47.36352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00000</th>\n",
       "      <td>35.31411</td>\n",
       "      <td>0.05033</td>\n",
       "      <td>-0.10388</td>\n",
       "      <td>0.29073</td>\n",
       "      <td>-0.20764</td>\n",
       "      <td>43.97381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00000</th>\n",
       "      <td>33.67059</td>\n",
       "      <td>0.03429</td>\n",
       "      <td>-0.13606</td>\n",
       "      <td>0.26228</td>\n",
       "      <td>-0.22331</td>\n",
       "      <td>42.98296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    loss   alpha     beta   gamma    theta      tau\n",
       "grp     ntm                                                        \n",
       "0.00000 1.00000 26.41085 0.09644  0.14230 0.26314 -0.22289 47.64495\n",
       "        2.00000 29.97449 0.00084  0.05753 0.28611 -0.27455 46.03194\n",
       "        3.00000 35.03755 0.07498 -0.05362 0.26680 -0.22383 43.17138\n",
       "1.00000 1.00000 24.69040 0.03072 -0.07529 0.29928 -0.15761 47.36352\n",
       "        2.00000 35.31411 0.05033 -0.10388 0.29073 -0.20764 43.97381\n",
       "        3.00000 33.67059 0.03429 -0.13606 0.26228 -0.22331 42.98296"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>theta</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grp</th>\n",
       "      <th>ntm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.00000</th>\n",
       "      <th>0.00000</th>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.00483</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>0.00786</td>\n",
       "      <td>0.00460</td>\n",
       "      <td>0.95740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00000</th>\n",
       "      <td>0.00206</td>\n",
       "      <td>0.00214</td>\n",
       "      <td>0.00676</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.00350</td>\n",
       "      <td>0.39201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00000</th>\n",
       "      <td>0.00556</td>\n",
       "      <td>0.00920</td>\n",
       "      <td>0.00283</td>\n",
       "      <td>0.00635</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>0.33874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00000</th>\n",
       "      <td>0.04239</td>\n",
       "      <td>0.00460</td>\n",
       "      <td>0.00974</td>\n",
       "      <td>0.01614</td>\n",
       "      <td>0.00410</td>\n",
       "      <td>1.45029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00000</th>\n",
       "      <td>0.02544</td>\n",
       "      <td>0.00383</td>\n",
       "      <td>0.00549</td>\n",
       "      <td>0.01364</td>\n",
       "      <td>0.01095</td>\n",
       "      <td>0.93639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00000</th>\n",
       "      <td>0.07887</td>\n",
       "      <td>0.00141</td>\n",
       "      <td>0.00155</td>\n",
       "      <td>0.00304</td>\n",
       "      <td>0.00281</td>\n",
       "      <td>0.46543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   loss   alpha    beta   gamma   theta     tau\n",
       "grp     ntm                                                    \n",
       "0.00000 0.00000 0.00541 0.00483 0.00712 0.00786 0.00460 0.95740\n",
       "        0.00000 0.00206 0.00214 0.00676 0.00419 0.00350 0.39201\n",
       "        0.00000 0.00556 0.00920 0.00283 0.00635 0.00494 0.33874\n",
       "        0.00000 0.04239 0.00460 0.00974 0.01614 0.00410 1.45029\n",
       "        0.00000 0.02544 0.00383 0.00549 0.01364 0.01095 0.93639\n",
       "        0.00000 0.07887 0.00141 0.00155 0.00304 0.00281 0.46543"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean = np.stack(gfdfs, axis=0).mean(axis=0)\n",
    "std = np.stack(gfdfs, axis=0).std(axis=0)\n",
    "mean_gfdf = gfdf.reset_index()\n",
    "mean_gfdf.loc[:, :] = mean\n",
    "\n",
    "std_gfdf = gfdf.reset_index()\n",
    "std_gfdf.loc[:, :] = std\n",
    "\n",
    "display(mean_gfdf.set_index(['grp','ntm']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Estimating parameters from group-level data (via KL divergence)\n",
    "\n",
    "### TODO:\n",
    "- Make sure the D_KL loss is computed appropriately (test on various vector pairs)\n",
    "- Try an exhaustive grid search of the sample space to see which regions correspond to minimal losses\n",
    "    - See if these \"good\" parameter space regions make sense\n",
    "- Build an interactive visualization (alpha and beta on the x, y axis, with grids colored according to loss value). TAU should be represented as a slider that should change the appearence of the 2d-alpha-beta grid.\n",
    "    - Try to visualize the data-simulation comparison histograms by selecting data by click_on event on the imshow object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %%snakeviz\n",
    "def DKL_loss(params, *args):\n",
    "    a, b, t = params\n",
    "    sids, data_beg, data_mid, data_end, init_data, simhits = args\n",
    "    \n",
    "    choices_beg = []\n",
    "    choices_mid = []\n",
    "    choices_end = []\n",
    "    for i, sid in enumerate(sids):\n",
    "        choices = sim_tools.simple_simulation(init_state=init_data[i, :, :], \n",
    "                                              win1=10, win2=9, N=250, \n",
    "                                              hits = simhits[i, :, :], \n",
    "                                              alpha=a, beta=b, \n",
    "                                              gamma=0, tau=t)\n",
    "        choices_beg.append(np.eye(4)[choices[:10].astype(int)])\n",
    "        choices_mid.append(np.eye(4)[choices[:250//2].astype(int)])\n",
    "        choices_end.append(np.eye(4)[choices.astype(int)])\n",
    "    choices_beg = np.stack(choices_beg).mean(axis=0).mean(axis=0)\n",
    "    choices_mid = np.stack(choices_mid).mean(axis=0).mean(axis=0)\n",
    "    choices_end = np.stack(choices_end).mean(axis=0).mean(axis=0)\n",
    "    DKL_beg = sp.special.kl_div(data_beg, choices_beg).sum()\n",
    "    DKL_mid = sp.special.kl_div(data_mid, choices_mid).sum()\n",
    "    DKL_end = sp.special.kl_div(data_end, choices_end).sum()\n",
    "    \n",
    "    loss = DKL_beg + DKL_mid + DKL_end\n",
    "    return loss\n",
    "\n",
    "\n",
    "df = lut.unpickle('supplementary/simple_choice_model/data/fit_data.pkl')\n",
    "df = df.loc[df.ntm != 0, :]\n",
    "data_dict = {'grp': [], 'ntm': [], 'loss': [], 'alpha': [], 'beta': [], 'gamma': [], 'tau': []}\n",
    "N_sim = 50\n",
    "N_trials = 250\n",
    "bounds = ([-1,1],[-1,1],[0,50])\n",
    "\n",
    "grp, ntm = 0, 3\n",
    "sids = df.loc[(df.grp==grp), 'sid'].unique()\n",
    "print('Estimating params for GRP-{}, NTM-{} ({}/{}) ...'.format(grp, ntm, N_sim, sids.size))\n",
    "sids = np.random.choice(sids, size=N_sim)\n",
    "\n",
    "data_beg = df.loc[(df.grp==grp) & (df.ntm==ntm) & (df.trial<=10), 'ch1':'ch4'].values.mean(axis=0)\n",
    "data_mid = df.loc[(df.grp==grp) & (df.ntm==ntm) & (df.trial<=249//2), 'ch1':'ch4'].values.mean(axis=0)\n",
    "data_end = df.loc[(df.grp==grp) & (df.ntm==ntm) & (df.trial>=1), 'ch1':'ch4'].values.mean(axis=0)\n",
    "\n",
    "hits_params = hits.get_parametric(grp=grp)\n",
    "trials = np.arange(N_trials) + 1\n",
    "probs = np.stack([1 / (1 + np.exp(-(hits_params[tid][0] + hits_params[tid][1]*trials))) for tid in [1,2,3,4]], axis=1)\n",
    "simhits = (np.random.rand(N_sim, N_trials, 4) <= probs).astype(int)\n",
    "init_data = sim_tools.get_multiple_sids(sids)\n",
    "data = (sids, data_beg, data_mid, data_end, init_data, simhits)\n",
    "\n",
    "# params = (0.14954,-0.11199,0.47016,11.34070)\n",
    "# params = (0.10445,-0.21977,0.47538,10.04687)\n",
    "init_guess = sim_tools.rand_params(bounds)\n",
    "# init_guess = gfdf.loc[(grp, ntm),'alpha':'tau'].values\n",
    "# DKL_loss(params, *data)\n",
    "\n",
    "opt_res = sp.optimize.minimize(fun=DKL_loss, \n",
    "                               x0=init_guess,\n",
    "                               args=data,\n",
    "                               bounds=bounds)\n",
    "print(init_guess)\n",
    "print(opt_res.x)\n",
    "# for grp in [0, 1]:\n",
    "#     for ntm in [1, 2, 3]: \n",
    "#         data_dict['grp'].append(grp)\n",
    "#         data_dict['ntm'].append(ntm)\n",
    "#         data_dict['loss'].append(opt_res.fun)\n",
    "#         data_dict['alpha'].append(opt_res.x[0])\n",
    "#         data_dict['beta'].append(opt_res.x[1])\n",
    "#         data_dict['gamma'].append(opt_res.x[2])\n",
    "#         data_dict['tau'].append(opt_res.x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def DKL_loss(params, *args):\n",
    "    a, b, t = params\n",
    "    sids, data_beg, data_mid, data_end, init_data, simhits = args\n",
    "    \n",
    "    choices_beg = []\n",
    "    choices_mid = []\n",
    "    choices_end = []\n",
    "    for i, sid in enumerate(sids):\n",
    "        choices = sim_tools.simple_simulation(init_state=init_data[i, :, :], \n",
    "                                              win1=10, win2=9, N=250, \n",
    "                                              hits = simhits[i, :, :], \n",
    "                                              alpha=a, beta=b, \n",
    "                                              gamma=0, tau=t)\n",
    "        choices_beg.append(np.eye(4)[choices[:10].astype(int)])\n",
    "        choices_mid.append(np.eye(4)[choices[:250//2].astype(int)])\n",
    "        choices_end.append(np.eye(4)[choices.astype(int)])\n",
    "    choices_beg = np.stack(choices_beg).mean(axis=0).mean(axis=0)\n",
    "    choices_mid = np.stack(choices_mid).mean(axis=0).mean(axis=0)\n",
    "    choices_end = np.stack(choices_end).mean(axis=0).mean(axis=0)\n",
    "    DKL_beg = sp.special.kl_div(data_beg, choices_beg).sum()\n",
    "    DKL_mid = sp.special.kl_div(data_mid, choices_mid).sum()\n",
    "    DKL_end = sp.special.kl_div(data_end, choices_end).sum()\n",
    "#     print(data_beg)\n",
    "#     print(choices_beg)\n",
    "#     print(data_mid)\n",
    "#     print(choices_mid)\n",
    "#     print(data_end)\n",
    "#     print(choices_end)\n",
    "    loss = DKL_beg + DKL_mid + DKL_end\n",
    "    return loss, [data_beg, data_mid, data_end], [choices_beg, choices_mid, choices_end]\n",
    "\n",
    "\n",
    "loss, _data, preds = DKL_loss(opt_res.x, *data)\n",
    "\n",
    "plt.figure('new', figsize=[9, 3])\n",
    "for i in range(3):\n",
    "    plt.subplot(131+i)\n",
    "    plt.plot([1,2,3,4], _data[i], c='k', ls='-')\n",
    "    plt.plot([1,2,3,4], preds[i], c='k', ls='--')\n",
    "    plt.ylim(0,.6)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
